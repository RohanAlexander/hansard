---
title: The Effect of Events on Discussion in the Australian Federal Parliament (1901--2017)
subtitle: 
author:
- Monica Alexander, University of Toronto\newline
- Rohan Alexander, Australian National University
date: 24 October 2018
institute: Presentation at SPIR, ANU.
output: binb::metropolis
fontsize: 12pt
---

```{r,setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

# Summary

## Approach

- Create a dataset of what was said in the Australian Federal Parliament from 1901 through to 2017 based on available public records. 
- Use a correlated topic model to reduce dimemsionality.
- Analyse the effect of various events using a Bayesian hierarchical Dirichlet model. 

## Findings

- Changes in government tend be associated with topic changes even when the party in power does not change;
- Elections that do not result in a change in government are rarely associated with topic changes; 
- Economic events, such as financial crises, have less significant effects than other events such as terrorist attacks; 
- and the effect of events is much more pronounced in the second half of our sample, and especially in the past two decades. 


# Data

## Hansard
- A daily text record called Hansard of what was said in the Australian Federal Parliament has been made available since it was established in 1901. It's not vertatim, but it's pretty close.
- Hansard records have been used in other counties but not really at scale in Australia.
- Daily PDFs are available Hansard records available online as PDFs and these are considered the official release. 
- There are 14,551 days worth of publicly available Hansard records across both chambers of the Australian Federal Parliament.

## Example PDF page

```{r pressureFig, echo=FALSE, out.width = '50%', fig.align="center"}

knitr::include_graphics("../../../figures/example_hansard_page.png")

```

## PDF parsing
- We use scripts written in R to convert the PDFs into daily text records.
- Some error is introduced at this stage because many of the records are in a two-column format that need to be separated, and the PDF parsing is not always accurate especially for older records e.g. 'the' is often parsed as 'thc'.
- We: remove numbers and punctuation; change the words to lower case; and concatenate multi-word names titles and phrases, such as new zealand to new_zealand. Then the sentences are de-constructed and each word considered individually.


# Model

## Latent Dirichlet Allocation - Overview

- The key assumption behind LDA is that each text, 'a document', in Hansard is made by speakers who decide the topics they would like to talk about in that document, and then choose words, 'terms', that are appropriate to those topics. 
- A topic could be thought of as a collection of terms, and a document as a collection of topics, where these collections are defined by probability distributions. 
- The topics are not specified *ex ante*; they are an outcome of the method - this is an unsupervised machine learning method.


## Latent Dirichlet Allocation - Example

Add figure
Statistically, LDA considers each document as having been generated by some probability distribution over topics. Similarly, each topic is considered a probability distribution over terms. To choose the terms used in each document, terms are picked from each topic in the appropriate proportion. 


## Latent Dirichlet Allocation - Data generation process

1. There are $1, 2, \dots, k, \dots, K$ topics and the vocabulary consists of $1, 2, \dots, V$ terms. For each topic, decide the terms that the topic uses by randomly drawing distributions over the terms. The distribution over the terms for the $k$th topic is $\beta_k$. Typically a topic would be a small number of terms and so the Dirichlet distribution with hyper-parameter $\boldsymbol{\eta}$ is used: $\beta_k \sim \mbox{Dirichlet}(\boldsymbol{\eta})$, where $\boldsymbol{\eta} = (\eta_1, \eta_2, \dots, \eta_{K})$. In practice, a symmetric Dirichlet distribution is usually used, where all elements of $\boldsymbol{\eta}$ are equal. 
2. Decide the topics that each document will cover by randomly drawing distributions over the $K$ topics for each of the $1, 2, \dots, d, \dots, D$ documents. The topic distributions for the $d$th document are $\theta_d$, and $\theta_{d,k}$ is the topic distribution for topic $k$ in document $d$. Again, the Dirichlet distribution with the hyper-parameter $0<\alpha<1$ is used here because usually a document would only cover a handful of topics: $\theta_d \sim \mbox{Dirichlet}(\boldsymbol{\alpha})$. Again, strictly $\boldsymbol{\alpha}$ is vector of length $K$ of hyper-parameters and they are usually equal.
3. If there are $1, 2, \dots, n, \dots, N$ terms in the $d$th document, then to choose the $n$th term, $w_{d, n}$:
    a. Randomly choose a topic for that term $n$, in that document $d$, $z_{d,n}$, from the multinomial distribution over topics in that document, $z_{d,n} \sim \mbox{Multinomial}(\theta_d)$.
    b. Randomly choose a term from the relevant multinomial distribution over the terms for that topic, $w_{d,n} \sim \mbox{Multinomial}(\beta_{z_{d,n}})$.


Given this set-up, the joint distribution for the variables is:
$$p(\beta_{1:K}, \theta_{1:D}, z_{1:D, 1:N}, w_{1:D, 1:N}) = \prod^{K}_{i=1}p(\beta_i) \prod^{D}_{d=1}p(\theta_d) \left(\prod^N_{n=1}p(z_{d,n}|\theta_d)p\left(w_{d,n}|\beta_{1:K},z_{d,n}\right) \right).$$

Based on this document generation process the analysis problem, discussed next, is to compute a posterior over $\beta_{1:K}$ and $\theta_{1:D}$, given $w_{1:D, 1:N}$. This is intractable directly, but can be approximated.


## Latent Dirichlet Allocation - Data generation process
- After the documents are created, they are all that we have to analyse. The term usage in each document, $w_{1:D, 1:N}$, is observed, but the topics are hidden, or 'latent'. We do not know the topics of each document, nor how terms defined the topics. In a sense we are trying to reverse the document generation process -- we have the terms and we would like to discover the topics.

If the earlier process around how the documents were generated is assumed and we observe the terms in each document, then we can obtain estimates of the topics. The outcomes of the LDA process are probability distributions and these define the topics. Each term will be given a probability of being a member of a particular topic, and each document will be given a probability of being about a particular topic. That is, we are trying to calculate the posterior distribution of the topics given the terms observed in each document:
$$p(\beta_{1:K}, \theta_{1:D}, z_{1:D, 1:N} | w_{1:D, 1:N}) = \frac{p\left(\beta_{1:K}, \theta_{1:D}, z_{1:D, 1:N}, w_{1:D, 1:N}\right)}{p(w_{1:D, 1:N})}.$$

The choice of the number of topics, *k*, drives the results and must be specified *a priori*. If there is a strong reason for a particular number, then this can be used. Otherwise, one way to choose an appropriate number is to use cross validation.

One weakness of the LDA method is that it considers a 'bag of words' where the order of those words does not matter. It is possible to extend the model to reduce the impact of the bag-of-words assumption and add conditionality to word order. Additionally, alternatives to the Dirichlet distribution can be used to extend the model to allow for correlation. This is the Correlated Topic Model, described in the next section.

## Correlated Topic Model
Slight modification of LDA - rather than assuming that the distribution of topics in a document, $\theta_d$, are a draw from a Dirichlet distribution, as in step 2 in LDA above, CTM assumes
$$\theta_d \sim \mbox{Logistic Normal}(\mu, \Sigma)$$
Essentially it swaps the Dirichlet for the Logistic Multivariate Normal. This sounds easy, but it's hard to implement.

The Structural Topic Model approach then adds a covariate to $\mu$ which allows consideration of additional information. 
$$\theta_d|X_d\gamma\Sigma \sim \mbox{Logistic Normal}(\mu = X_d\gamma, \Sigma)$$
Again, sounds easy, but hard to implement and they implement a very nice algorithm.

## Correlated Topic Model - Example output

```{r exampletopics, cache = TRUE, echo=FALSE, out.width = '100%'}
knitr::include_graphics("../../../figures/topics_example.pdf")
```


## Why not STM?
- No way to specify more complicated auto-correlated functional forms of the effects of events over time. 
- There is no way to implement partial pooling across groups of similar documents. 
- There is no way of identifying 'outlying' topic distributions -- and therefore events that had an important effect -- without pre-specifying the event of interest in the model.

## Analysis model
Specifically, we use the estimated topic distributions from the CTM described in the previous section as an input into a Bayesian hierarchical Dirichlet regression framework, which relates the proportions of each topic to underlying time trends, changes in governments and elections. This set-up also allows us to identify 'outlying' topic distributions and relate these to other events. 

Define $\theta_{dp}$ to be the proportion of topic of topic $p$ on day $d$. Note that the $\theta_{d,1:P}$ for $p = 1,2,\dots P=40$ are equal to the estimated values of $\theta_d$ from the CTM. We assume that the majority of variation in topics is across sitting periods $s$, where a sitting period is defined as any group of days that are less than one week apart. Using this definition, there are a total of 745 sitting periods over the period 1901 to 2017 inclusive.

The topic proportions on day $d$ are modelled in reference to their membership of a particular sitting period $s$. Firstly, we assume that each distribution of topics, $\theta_{d,1:P}$ for each day is a draw from a Dirichlet distribution with mean parameter $\mu_{s[d],1:P}$:

$$
\theta_{d,1:P} \sim \mbox{Dirichlet}(\mu_{s[d],1:P})
$$
where the notation $s[d]$ refers to the sitting period $s$ to which day $d$ belongs. This distributional assumption accounts for the fact that on any given day, the sum of all proportions in each topic must equal 1. 

The goal of the model is to relate these proportions to government $g$ at time $d$, and also the days since the most recent election, $e$, while account for underlying time trends. The mean parameters $\mu_{sp}$ are modelled on the log scale as

$$
\log \mu_{s,p} = \alpha_{g[s],p} + \cdot\alpha_{e[s],d,p}  + \sum_{k=1}^{K} \beta_{p,k} \cdot x_{s,k} + \delta_{s,p}
$$
where:

- $\alpha_{g[s],p}$ is the mean effect for government $g$ (which covers sitting period $s$) and topic $p$;
- $\alpha_{e[s],d,p}$ is the effect of election $e$ (which occurs in sitting period $s$) for topic $p$ on day $d$ since the election;
- $\sum_{k=1}^{K} \beta_{p,k} \cdot x_{s,k}$ is the underlying time trend, modelled using splines: $x_{s,k}$ is the $k$th basis spline in sitting period $s$ and $\beta_{p,k}$ is a coefficient on the $k$th basis spline; and
- $\delta_{s,p}$ is a structured random, or levels, effect for each sitting period and topic. 

The government term $\alpha_{g[s],p}$ assumes there is some underlying mean effect of each government on the topic distribution. We place uninformative priors on each of these parameters:
$$
\alpha_{g[s],p} \sim \mbox{Normal}(0, 100)
$$

The election term $\alpha_{e[s],d,p}$ assumes there is an initial effect of an election on the topic distribution, which then decays as a function of days since election, $d$. In particular, we model this as an AR(1) in $d$:

$$
\alpha_{e[s],d,p} = \rho_{e[s],p} \cdot \alpha_{e[s],d-1,p}
$$
The value of the initial effect, $\alpha_{e[s],0,p}$, and the AR(1) term, $\rho$, both have non-informative priors:

$$
\alpha_{e[s],0,p} \sim \mbox{Normal}(0, 100)
$$
$$
\rho_{e[s],p} \sim \mbox{Uniform}(0,1)
$$
We model the underlying time trend in topics using splines regression. The intuition behind this term is to capture the underlying non-linear trend in topic distributions over time, which is caused by large-scale structural changes in the economy, and Australian society and culture. The $x_{s,k}$ for $k = 1,2,\dots, K$ are the value of cubic basis splines for sitting period $s$ at knot point $k$. We place knot points every five sitting periods as this is the average length of time for a government to sit (**CHECK**). Non-informative priors are placed on the splines coefficients:
$$
\beta_{p,k} \sim \mbox{Normal}(0, 100)
$$

Finally, the sitting period-specific random effect $\delta_{s,p}$ allows for the topic distributions in some sitting periods to be different than expected based on government and election effects. This allows us to identify large deviations away from the expected distribution, thus helping to identify the effect of other, non-government and non-election events. In addition, this set up also partially pools effects across sitting periods. The $\delta_{s,p}$ values are modelled as:

$$
\delta_{s,p} \sim \mbox{Normal}(0, \sigma_{e[s],p}^2)
$$

The variance parameters $\sigma_{e[s],p}^2$ give an indication of the how the variation in topics is changing over election periods. If the estimates of the variance are larger, then there is more variation in the topics discussed within an election period. Non-informative priors are placed on the variance parameters:

$$
\sigma_{e[s],p} \sim \mbox{Uniform}(0,3)
$$

We run the model in JAGS using the \texttt{rjags} package.




# Results



# Future work

## Future work
- Group identity: which is more important?
-

## Questions?
- rohan.alexander@anu.edu.au
- @RohanAlexander
- rohanalexander.com




## Typography

```
The theme provides sensible defaults to
\emph{emphasize} text, \alert{accent} parts
or show \textbf{bold} results.

In Markdown, you can also use _emphasize_ and **bold**.
```

\begin{center}becomes\end{center}

The theme provides sensible defaults to \emph{emphasize} text,
\alert{accent} parts or show \textbf{bold} results.

In Markdown, you can also use _emphasize_ and **bold**.


## Math

\begin{equation*}
    e = \lim_{n\to \infty} \left(1 + \frac{1}{n}\right)^n
\end{equation*}


## R Figure Example

The following code generates the plot on the next slide (taken from
`help(bxp)` and modified slightly):

```{r pressureCode, eval=FALSE}
library(stats)
set.seed(753)
bx.p <- boxplot(split(rt(100, 4),
                      gl(5, 20)), plot=FALSE)
bxp(bx.p, notch = FALSE, boxfill = "lightblue",
    frame = FALSE, outl = TRUE,
    main = "Example from help(bxp)")
```  




## R Table Example
  
A simple `knitr::kable` example:  

```{r kableEx}
knitr::kable(mtcars[1:5, 1:8],
             caption="(Parts of) the mtcars dataset")
```

## Resources

### For more information:
- See the [Metropolis repository](https://github.com/matze/mtheme) for more on Metropolis
- See the [RMarkdown repository](https://github.com/rstudio/rmarkdown) for more on RMarkdown
- See the [binb repository](https://github.com/eddelbuettel/binb) for more on binb 
- See the [binb vignettes](https://github.com/eddelbuettel/binb/vignettes) for more examples.
